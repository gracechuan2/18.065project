{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNModelsAttempt2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg7FVAJoxmnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdp36PQP7LoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTu1qcoT7r-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxZyJwAJ7vvt",
        "colab_type": "code",
        "outputId": "82e6bd97-59a1-4bfb-bf04-5803c5b67094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "df = pd.read_csv(\"dataset_18065.csv\")\n",
        "df.head()\n",
        "tiers = df.Tier\n",
        "low_df = df[df['Tier'] == '0']\n",
        "mid_df = df[df['Tier'] == '1']\n",
        "high_df = df[df['Tier'] == '2']\n",
        "features = ['year', 'VAA', 'PSNV', 'GE', 'RQ', 'RL', 'CC']\n",
        "\n",
        "for i in low_df.index:\n",
        "  for f in features:\n",
        "    low_df.loc[i, f] = low_df.loc[i, f].astype(float)\n",
        "  try:\n",
        "    low_df.loc[i, 'GDPgrowth'] = float(low_df.loc[i, 'GDPgrowth'])\n",
        "  except ValueError:\n",
        "    low_df.loc[i, 'GDPgrowth'] = float('nan')\n",
        "\n",
        "\n",
        "print(low_df.GDPgrowth)\n",
        "\n",
        "for i in mid_df.index:\n",
        "  for f in features:\n",
        "    mid_df.loc[i, f] = mid_df.loc[i, f].astype(float)\n",
        "  try:\n",
        "    mid_df.loc[i, 'GDPgrowth'] = float(mid_df.loc[i, 'GDPgrowth'])\n",
        "  except ValueError:\n",
        "    mid_df.loc[i, 'GDPgrowth'] = float('nan')\n",
        "  \n",
        "\n",
        "for i in high_df.index:\n",
        "  for f in features:\n",
        "    high_df.loc[i, f] = high_df.loc[i, f].astype(float)\n",
        "  try:\n",
        "    high_df.loc[i, 'GDPgrowth'] = float(high_df.loc[i, 'GDPgrowth'])\n",
        "  except ValueError:\n",
        "    high_df.loc[i, 'GDPgrowth'] = 0.0\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1           NaN\n",
            "11      4.44652\n",
            "13      4.64447\n",
            "14        4.353\n",
            "29      3.61654\n",
            "         ...   \n",
            "3456    5.12212\n",
            "3463   -2.70147\n",
            "3466    5.75793\n",
            "3467     3.7949\n",
            "3468    6.15919\n",
            "Name: GDPgrowth, Length: 925, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu9UbC7QiHqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaning data\n",
        "df = pd.read_csv(\"dataset_18065.csv\")\n",
        "df = df.drop(['country', 'country_abb'], axis=1)\n",
        "drop_row_indices = []\n",
        "for i, row in df.iterrows():\n",
        "    for j, col in row.iteritems():\n",
        "        try:\n",
        "            row[j] = float(col)\n",
        "        except ValueError:\n",
        "            # print(\"ValueError\")\n",
        "            drop_row_indices.append(i)\n",
        "            continue\n",
        "        if math.isnan(row[j]):\n",
        "            drop_row_indices.append(i)\n",
        "df = df.drop(drop_row_indices, axis = 0)\n",
        "GDP_growth=df['GDPgrowth']\n",
        "\n",
        "tiers = df.Tier\n",
        "low_df = df[df['Tier'] == '0']\n",
        "mid_df = df[df['Tier'] == '1']\n",
        "high_df = df[df['Tier'] == '2']\n",
        "features = ['year', 'VAA', 'PSNV', 'GE', 'RQ', 'RL', 'CC']\n",
        "\n",
        "\n",
        "# making tiers indicator variables\n",
        "df['Tier'] = df['Tier'].map({'0': 'Low', '1': 'Mid', '2': 'High'})\n",
        "df = pd.get_dummies(df, prefix_sep='')\n",
        "df = df.drop(labels=df.columns[10:], axis=1)\n",
        "df = pd.concat([df, GDP_growth], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TGHH-cDnwq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['year', 'VAA', 'PSNV', 'GE', 'RQ', 'RL', 'CC']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-3bdW1vAPpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device configuration\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQbCev72AYbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8o2sTfpBgKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_size = len(features)\n",
        "# hidden_size = input_size\n",
        "# num_classes = 1 # size of output\n",
        "\n",
        "low_tier_X = low_df.loc[:, features]\n",
        "low_tier_y = low_df.GDPgrowth\n",
        "\n",
        "# print(len(low_tier_X))\n",
        "\n",
        "mid_tier_X = mid_df.loc[:, features]\n",
        "mid_tier_y = mid_df.GDPgrowth\n",
        "\n",
        "# print(len(mid_tier_X))\n",
        "\n",
        "high_tier_X = high_df.loc[:, features]\n",
        "high_tier_y = high_df.GDPgrowth\n",
        "\n",
        "low_X_train, low_X_test, low_y_train, low_y_test = train_test_split(np.asarray(low_tier_X).astype(np.float32),\n",
        "                                                                    np.asarray(low_tier_y).astype(np.float32), test_size = .15)\n",
        "\n",
        "mid_X_train, mid_X_test, mid_y_train, mid_y_test = train_test_split(np.asarray(mid_tier_X).astype(np.float32),\n",
        "                                                                    np.asarray(mid_tier_y).astype(np.float32), test_size = .15)\n",
        "\n",
        "high_X_train, high_X_test, high_y_train, high_y_test = train_test_split(np.asarray(high_tier_X).astype(np.float32),\n",
        "                                                                        np.asarray(high_tier_y).astype(np.float32), test_size = .15)\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(np.asarray(X).astype(np.float32), \n",
        "#                                                     np.asarray(y).astype(float32), test_size = .15)\n",
        "# X_train = torch.tensor(X_train)\n",
        "# X_test = torch.tensor(X_test)\n",
        "# y_train = torch.tensor(y_train)\n",
        "# y_test = torch.tensor(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWUyaSwWvVPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "low_X_train, low_X_test = torch.tensor(low_X_train), torch.tensor(low_X_test)\n",
        "low_y_train, low_y_test = torch.tensor(low_y_train), torch.tensor(low_y_test)\n",
        "\n",
        "mid_X_train, mid_X_test = torch.tensor(mid_X_train), torch.tensor(mid_X_test)\n",
        "mid_y_train, mid_y_test = torch.tensor(mid_y_train), torch.tensor(mid_y_test)\n",
        "\n",
        "high_X_train, high_X_test = torch.tensor(high_X_train), torch.tensor(high_X_test)\n",
        "high_y_train, high_y_test = torch.tensor(high_y_train), torch.tensor(high_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC2zDhxvxln9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "low_train_dataset = Data.TensorDataset(low_X_train, low_y_train)\n",
        "low_test_dataset = Data.TensorDataset(low_X_test, low_y_test)\n",
        "\n",
        "mid_train_dataset = Data.TensorDataset(mid_X_train, mid_y_train)\n",
        "mid_test_dataset = Data.TensorDataset(mid_X_test, mid_y_test)\n",
        "\n",
        "high_train_dataset = Data.TensorDataset(high_X_train, high_y_train)\n",
        "high_test_dataset = Data.TensorDataset(high_X_test, high_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pXZ4y6pyAN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper-parameters \n",
        "input_size = len(features)\n",
        "hidden_size = len(features)\n",
        "num_classes = 1\n",
        "num_epochs = 100\n",
        "batch_size = 200\n",
        "learning_rate = 0.8\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        #self.linear = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        #out = self.linear(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=high_train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=high_test_dataset, \n",
        "                                          batch_size=1, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5F6EmYW0UMF",
        "colab_type": "code",
        "outputId": "39583fcd-88e1-4a3e-d4f0-4f230bfd08b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "\n",
        "#print(\"hi!)\")\n",
        "train_loss = 0\n",
        "#print(\"train_loss: \", train_loss)\n",
        "for epoch in range(num_epochs):\n",
        "  #print(\"in for loop\")\n",
        "  for entry in enumerate(train_loader): # for each training step\n",
        "    batch_x = entry[1][0]\n",
        "    batch_y = entry[1][1]\n",
        "    # Converting to correct data type\n",
        "    b_x = Variable(batch_x)\n",
        "    #print(b_x)\n",
        "    b_y = Variable(batch_y)\n",
        "\n",
        "    #forward pass\n",
        "    ypred = model(batch_x)\n",
        "    #print(ypred)\n",
        "    loss = loss_func(ypred,b_y)\n",
        "    #print(\"loss: \", loss)\n",
        "    train_loss += loss\n",
        "\n",
        "    #Backpropogation \n",
        "    optimizer.zero_grad() \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "#print(\"train_loss = \", train_loss/(num_epochs * rounds))\n",
        "\n",
        "# total_loss = 0\n",
        "# #rounds = 0\n",
        "# for epoch in range(num_epochs):\n",
        "#   rounds = 0\n",
        "#   for entry in enumerate(test_loader): # for each training step\n",
        "#     #print(entry)\n",
        "#     #Move tensors to the configured device\n",
        "#     batch_x = entry[1][0]\n",
        "#     batch_y = entry[1][1]\n",
        "#     b_x = Variable(batch_x)\n",
        "#     b_y = Variable(batch_y)\n",
        "\n",
        "#     rounds += 1\n",
        "#     #forward pass\n",
        "#     ypred = model(batch_x)\n",
        "#     #print(ypred)\n",
        "#     loss = loss_func(ypred,batch_y)\n",
        "#     total_loss+=loss\n",
        "#     #print(loss)\n",
        "# av_loss = total_loss/(num_epochs*rounds)\n",
        "\n",
        "rounds=0\n",
        "total_loss = 0\n",
        "for step, (batch_x,batch_y) in enumerate(test_loader): # for each training step\n",
        "  rounds+=1\n",
        "  #forward pass\n",
        "  ypred = model(batch_x)\n",
        "  loss = loss_func(ypred,batch_y)\n",
        "  total_loss +=loss\n",
        "  \n",
        "av_loss = total_loss/rounds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([200])) that is different to the input size (torch.Size([200, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "likGuAgFeyes",
        "colab_type": "code",
        "outputId": "c65e2077-4950-4b8c-a5fc-016d27f04414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(av_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(14.7029, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pViB-ebv1Txc",
        "colab_type": "code",
        "outputId": "7ab05077-41c2-417e-b59d-797194bb3050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2138, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbCpubZqBE0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "high DS\n",
        "lr = .15, batch size 10, error = 14.8162\n",
        "batch size 100, error = 14.7104\n",
        "batch size 200, error = 14.84\n",
        "\n",
        "lr = .5, batch size = 10, error = 15.4074\n",
        "batch size = 100, error = 14.66\n",
        "batch size = 200, error = 14.74\n",
        "\n",
        "lr = .8, batch size = 10, error = 15.00\n",
        "batch size 100, error = 14.81\n",
        "batch size 200, error = 14.70\n",
        "__________________\n",
        "\n",
        "lr = .15 batch size 10: error = 19.0653\n",
        "100, error = 18.0683 \n",
        "200, error = 18.1770\n",
        "\n",
        "lr = .5\n",
        "batch size 200, error = 18.3277\n",
        "batch size 100, error = 20.4618\n",
        "batch size 10, error = 18.3074\n",
        "\n",
        "lr = .8\n",
        "batch size 10, error = 18.154\n",
        "batch size 100, error = 18.2751\n",
        "batch size 200, error = 18.3092\n",
        "__________\n",
        "\n",
        "lr = .15, batch size 10, error = 17.42\n",
        "batch size 100, error = 16.98\n",
        "batch size 200, error = 16.96\n",
        "\n",
        "lr = .5, batch size 10, error = 17.77\n",
        "batch size 100, error = 18.94\n",
        "batch size 200, error = 22.67\n",
        "\n",
        "lr = .8, batch size = 10, error = 20.3421\n",
        "batch size = 100, error = 24.10\n",
        "batch size = 200, error = 18.12\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}